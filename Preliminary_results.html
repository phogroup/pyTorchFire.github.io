---
layout: page
mathjax: true
title: " "
---

<h1><strong>Demos and preliminary results</strong></h1>
<h2>Problem settings</h2>
<h4><em>Solving heat equation with neural network:</em></h4>
<p>In this problem, we learn the neural network to solve for the temperature <img src="https://i.upmath.me/svg/u" alt="u" /> given arbitrary conductivity field <img src="https://i.upmath.me/svg/%5Ckappa" alt="\kappa" />. The 2D heat equation is written as follows</p>
<div align="center"><img align="center" src="https://i.upmath.me/svg/%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%20%20%20%20%20-%5Cnabla%20%5Ccdot%20%5Cleft%20.(%20%7Be%5E%5Ckappa%20%5Cnabla%20u%7D%20%5Cright.)%20%26%20%3D%20f%20%20%5Cquad%20%5Ctext%7Bin%20%7D%20%5COmega%20%3D%20%5Cleft%20.%5B%20%7B0%2C1%7D%5E2%20%5Cright.%5D%5C%5C%0A%20%20%20%20%20%20%20%20u%20%26%20%3D%200%20%5Cquad%20%5Ctext%7B%20on%20%7D%20%5CGamma%5E%7B%5Ctext%7Bext%7D%7D%20%5C%5C%0A%20%20%20%20%20%20%20%20%5Ctextbf%7Bn%7D%20%5Ccdot%20%5Cleft.(%7Be%5E%5Ckappa%20%5Cnabla%20u%7D%5Cright.)%20%26%20%3D%200%20%5Cquad%20%5Ctext%7B%20on%20%7D%20%5CGamma%5E%7B%5Ctext%7Broot%7D%7D%2C%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
         -\nabla \cdot \left .( {e^\kappa \nabla u} \right.) &amp; = f  \quad \text{in } \Omega = \left .[ {0,1}^2 \right.]\\
        u &amp; = 0 \quad \text{ on } \Gamma^{\text{ext}} \\
        \textbf{n} \cdot \left.({e^\kappa \nabla u}\right.) &amp; = 0 \quad \text{ on } \Gamma^{\text{root}},
\end{aligned}
" /></div>
<h4><em>Results: comparison of solutions by Firedrake and TorchFire neural network</em></h4>
<div align="center"><img width="500" height="300" src="assets\figures\Heat_eq\Mixed.png"></div>
<h4><center>Figure 1: Training loss and test accuracy versus the training epochs</center></h4>

<div align="center"><img width="1050" height="320" src="assets\figures\Heat_eq\Animations.gif"></div>
<h4><center>Figure 2: (Left) conductivity field, (Middle) True solution obtained by Firedrake software, (Right) Predicted solution obtained by TorchFire neural network</center></h4>

<div align="left">
<h2><em>Example code, TorchFire</em></h2>
<pre><code class="language-python"># Step 0: Import necessary packges
from torchfire import fd_to_torch
import firedrake
import torch
from torch import nn
import pandas

# Step 1: Load train and test data
kappa_train, kappa_test, u_test = pandas.read_csv(...).to_numpy()

# Step 2: TorchFire physic module
## Firedrake Mesh and Space definition
nx, ny = 15, 15
mesh = UnitSquareMesh(nx, ny)
V = FunctionSpace(mesh, &quot;P&quot;, 1)

## Boudary connditions
bc = DirichletBC(V, 0, (1, 2, 3))
## Weak form definition
def assemble_firedrake(u, kappa):
    x = SpatialCoordinate(mesh)
    v = TestFunction(u.function_space())
    f = Constant(20.0)
    return assemble(inner(exp(kappa) * grad(u), grad(v)) * dx - inner(f, v) * dx, bcs=bc)
    
## Torchfire wrapper for assemble_firedrake
templates = (firedrake.Function(V), firedrake.Function(V))
residualTorch = fd_to_torch(assemble_firedrake, templates, &quot;residualTorch&quot;).apply

# Step 3: Neural network model
class NeuralNetwork(nn.Module):
    def __init__(self, kappa_dim, u_dim, neurons):
        super(NeuralNetwork, self).__init__()
        self.Neuralmap1 = nn.Linear(kappa_dim, neurons)
        self.Relu = nn.ReLU()
        self.Neuralmap2 = nn.Linear(neurons, u_dim)
        self.MSE = nn.MSELoss()

    def forward(self, kappa):
        u = self.Neuralmap2(self.Relu(self.Neuralmap1(kappa)))
        return u
        
    def ResidualTorch(self, u, kappa):
        residuals = residualTorch(u, kappa)
        Physic_loss = self.MSE(residuals, torch.zeros_like(residuals))
        return Physic_loss
        
model = NeuralNetwork(kappa_dim = (nx+1)*(ny+1), u_dim = (nx+1)*(ny+1), neurons = 1000)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# Step 4 Define train and test function for learning
def train_loop(model, optimizer, kappa):
    train_loss = 0
    for batch in range(int(num_train / batch_size)):
        u_pred = model(kappa[(batch) * batch_size:(batch + 1) * batch_size, :])
        residuals = model.ResidualTorch(u_pred, kappa) / batch_size
        
        # Backpropagation
        optimizer.zero_grad(), residuals.backward(), optimizer.step(),
        train_loss += residuals
    return train_loss
        
def test_loop(model, kappa_test, u_test):
    with torch.no_grad():
        u_pred = model(kappa_test)
        test_acc = (torch.linalg.vector_norm(u_pred - u_test, dim=-1)**2
                    / torch.linalg.vector_norm(u_test, dim=-1)**2).mean()
    return test_acc

for _ in range(nEpochs):
    train_loss = train_loop(model, optimizer, kappa_train)
    test_acc = test_loop(model, kappa_test, u_test)
</code></pre>
</div>